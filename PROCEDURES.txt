INSTALLATION PROCEDURE
----------------------

- Linux OS prefered
- Docker (optional)
- ElasticSearch (optionally on Docker)
- Kibana (optionally on Docker)
- Python3 + Python virtual environment + libraries
- Activate Guardium GBDI "Full SQL Nodep" Datamart
- git clone CT22_EK_FullSQL
- update the param_data.json file to your needs/set up
- Prepare the following 2 csv files:
	- A_DB_USERS.csv - Must have the column "DB User Name" + any other column 
        - A_IPs.csv - Must have at least 2 columns : "Hostname" & "IP" for each node (client or server) + any other column - Make sure there is no duplicate in the t-uple Hostname/IP
        2 examples of such file are provided.
- Upload in Kibana the following 3 csv files:
	- A_SEL_TYP.csv as a_sel_typ index
	- A_IPs.csv as a_ips index
	- A_DB_USERS.csv as a_db_users index
- cron the execution of the python program by collectors or group of collectors :
	- example:
        ./FullSQLEnrich_X_EK.py xxxxx    with xxxx a pattern to recognize a/several collectors
        if collectors are named like dcprodx00x  with x = digit (dcprodx001, dcprodx002, dcprodx003 ....)
        ./FullSQLEnrich_X_EK.py dcprodx00
        this will process the ddatamart files of ALL collectors whose name contains dcprodx00
        - sync the execution of the python program with the receiving of the datamart like 5 minutes later.


Deletion of specific records
----------------------------

POST /enriched_full_sql/_delete_by_query?pretty
{
  "query": {
    "match": {
      "doc.Confidence Level": "20"
    }
  }
}
